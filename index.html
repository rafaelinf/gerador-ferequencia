<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Aura Harmonics - Gerador de Tons</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body { font-family: Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial; background:#111827; color:#f3f4f6; }
    ::-webkit-scrollbar { width:8px; }
    ::-webkit-scrollbar-track { background:#1f2937; }
    ::-webkit-scrollbar-thumb { background:#4b5563; border-radius:4px; }
    ::-webkit-scrollbar-thumb:hover { background:#6b7280; }
    .export-status { min-height: 1.5em; }
  </style>
</head>
<body class="antialiased">
  <div id="root"></div>

  <!-- Usamos mÃ³dulos ESM para React/ReactDOM (esm.sh CDN) -->
  <script type="module">
    import React from "https://esm.sh/react@18.2.0";
    import { createRoot } from "https://esm.sh/react-dom@18.2.0/client";

    /************ Constants & Types ************/
    const ToneType = {
      ISOCHRONIC: "Isochronic",
      BINAURAL: "Binaural",
      MONAURAL: "Monaural"
    };

          // FunÃ§Ã£o para detectar dispositivos mÃ³veis
      const isMobileDevice = () => {
        return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ||
               (navigator.maxTouchPoints && navigator.maxTouchPoints > 2) ||
               window.innerWidth <= 768;
      };

      // FunÃ§Ã£o para detectar iOS especificamente
      const isIOS = () => {
        return /iPad|iPhone|iPod/.test(navigator.userAgent) || 
               (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
      };

      // FunÃ§Ã£o para detectar Android
      const isAndroid = () => {
        return /Android/.test(navigator.userAgent);
      };

    const DEFAULT_VOLUME = 0.5;
    const DEFAULT_ISOCHRONIC_SETTINGS = { carrierFreq: 136.1, pulseFreq: 7.83 };
    const DEFAULT_BINAURAL_SETTINGS = { baseFreq: 100, beatFreq: 10 };
    const DEFAULT_MONAURAL_SETTINGS = { freq1: 200, freq2: 205 };
    const FREQUENCY_RANGES = {
      carrierFreq: { min: 20, max: 1500, step: 0.1 },
      pulseFreq:   { min: 0.5, max: 40, step: 0.1 },
      baseFreq:    { min: 20, max: 1500, step: 0.1 },
      beatFreq:    { min: 0.5, max: 50, step: 0.1 },
      freq1:       { min: 20, max: 1500, step: 0.1 },
      freq2:       { min: 20, max: 1500, step: 0.1 }
    };

    const TONE_TYPES_CONFIG = [
      { id: ToneType.ISOCHRONIC, label: 'Tons IsocrÃ´nicos' },
      { id: ToneType.BINAURAL, label: 'Batidas Binaurais' },
      { id: ToneType.MONAURAL, label: 'Batidas Monaurais' }
    ];

    const DEFAULT_EXPORT_DURATION_MINUTES = 5;
    const MIN_EXPORT_DURATION_MINUTES = 1;
    const MAX_EXPORT_DURATION_MINUTES = 120;

    const PRESETS = [
      { id:'focusAlphaBinaural', name:"Foco (Alpha Binaural)", description:"Para clareza mental", toneType: ToneType.BINAURAL, settings:{ baseFreq:100, beatFreq:10 } },
      { id:'meditationThetaBinaural', name:"MeditaÃ§Ã£o (Theta Binaural)", description:"Relaxamento profundo", toneType: ToneType.BINAURAL, settings:{ baseFreq:136.1, beatFreq:6 } },
      { id:'solfeggio528Iso', name:"Solfeggio 528Hz (Iso)", description:"EquilÃ­brio emocional", toneType: ToneType.ISOCHRONIC, settings:{ carrierFreq:528, pulseFreq:7.83 } },
      { id:'solfeggio396Monaural', name:"Solfeggio 396Hz (Mon)", description:"LiberaÃ§Ã£o de medos", toneType: ToneType.MONAURAL, settings:{ freq1:396, freq2:398 } },
      { id:'astralProjectionThetaIso', name:"ProjeÃ§Ã£o Astral (Theta Iso)", description:"Estados alterados", toneType: ToneType.ISOCHRONIC, settings:{ carrierFreq:100, pulseFreq:4.5 } },
      { id:'healingGeneralIso', name:"Cura Geral (432Hz Iso)", description:"HarmonizaÃ§Ã£o", toneType: ToneType.ISOCHRONIC, settings:{ carrierFreq:432, pulseFreq:10 } }
    ];

    /************ ParameterInput Component ************/
    function ParameterInput({ label, id, value, onChange, min, max, step = 0.1, unit = "Hz", tooltip = "" }) {
      const [inputValue, setInputValue] = React.useState(String(value));
      const inputRef = React.useRef(null);

      React.useEffect(() => {
        if (inputRef.current !== document.activeElement) setInputValue(String(value));
      }, [value]);

      const handleChange = (e) => {
        const currentStr = e.target.value;
        setInputValue(currentStr);
        if (currentStr === "" || currentStr === "-" || currentStr.endsWith(".")) return;
        const numeric = parseFloat(currentStr);
        if (!isNaN(numeric)) {
          let clamped = numeric;
          if (typeof min === 'number' && isFinite(min) && clamped < min) clamped = min;
          if (typeof max === 'number' && isFinite(max) && clamped > max) clamped = max;
          if (clamped !== value) onChange(clamped);
        }
      };

      const handleBlur = () => {
        let cur = inputValue;
        let numeric = parseFloat(cur);
        let finalVal;
        const numMinDefined = typeof min === 'number' && isFinite(min);
        const numMaxDefined = typeof max === 'number' && isFinite(max);

        if (cur === "") finalVal = numMinDefined ? min : 0;
        else if (isNaN(numeric)) finalVal = value;
        else {
          if (numMinDefined && numeric < min) finalVal = min;
          else if (numMaxDefined && numeric > max) finalVal = max;
          else finalVal = numeric;
        }

        if (typeof step === 'number' && step > 0 && isFinite(finalVal)) {
          finalVal = Math.round(finalVal / step) * step;
          const dp = (String(step).split('.')[1] || '').length;
          if (dp > 0) finalVal = parseFloat(finalVal.toFixed(dp));
        }

        setInputValue(String(finalVal));
        if (finalVal !== value) onChange(finalVal);
      };

      return (
        React.createElement("div", null,
          React.createElement("label", { 
            htmlFor: id, 
            className: "block text-sm font-medium text-gray-300 mb-1",
            title: tooltip || `Ajuste o valor de ${label.toLowerCase()}. Valor mÃ­nimo: ${min}, mÃ¡ximo: ${max}, passo: ${step}`
          }, label),
          React.createElement("div", { className: "relative" },
            React.createElement("input", {
              ref: inputRef,
              id, name: id, type: "text", inputMode: "decimal",
              value: inputValue, onChange: handleChange, onBlur: handleBlur,
              "aria-valuemin": typeof min === 'number' && isFinite(min) ? min : undefined,
              "aria-valuemax": typeof max === 'number' && isFinite(max) ? max : undefined,
              className: "w-full px-3 py-2 bg-gray-800 border border-gray-600 rounded-md shadow-sm text-gray-100 placeholder-gray-500 focus:outline-none focus:ring-2 focus:ring-violet-500 sm:text-sm"
            }),
            unit && React.createElement("span", { className: "absolute inset-y-0 right-0 pr-3 flex items-center text-sm text-gray-500 pointer-events-none" }, unit)
          )
        )
      );
    }

    /************ Audio Engine Hook (useAudioEngine) ************/
    function useAudioEngine() {
      const [isPlaying, setIsPlaying] = React.useState(false);
      const audioContextRef = React.useRef(null);
      const masterGainRef = React.useRef(null);

      const osc1Ref = React.useRef(null);
      const osc2Ref = React.useRef(null);
      const panner1Ref = React.useRef(null);
      const panner2Ref = React.useRef(null);
      const isochronicCarrierGainRef = React.useRef(null);
      const pulseLFORef = React.useRef(null);
      const lfoModulatorGainRef = React.useRef(null);
      const currentPlayingTypeRef = React.useRef(null);

      const ensureAudioContext = React.useCallback(async () => {
        if (!audioContextRef.current) {
          try {
            // Criar AudioContext com fallback para navegadores mais antigos
            const AudioContextClass = window.AudioContext || window.webkitAudioContext;
            if (!AudioContextClass) {
              throw new Error('Web Audio API nÃ£o suportada neste navegador');
            }
            
            audioContextRef.current = new AudioContextClass();
            masterGainRef.current = audioContextRef.current.createGain();
            masterGainRef.current.connect(audioContextRef.current.destination);
            
            // Log para debug
            console.log('âœ… AudioContext criado:', audioContextRef.current.state);
            console.log('ðŸ“± Dispositivo:', isMobileDevice() ? 'MÃ³vel' : 'Desktop');
            console.log('ðŸŽ iOS:', isIOS() ? 'Sim' : 'NÃ£o');
            console.log('ðŸ¤– Android:', isAndroid() ? 'Sim' : 'NÃ£o');
          } catch (error) {
            console.error('âŒ Erro ao criar AudioContext:', error);
            throw new Error('NÃ£o foi possÃ­vel inicializar o sistema de Ã¡udio');
          }
        }
        
        // Resolver AudioContext se estiver suspenso
        if (audioContextRef.current.state === 'suspended') {
          try {
            console.log('ðŸ”„ Tentando resumir AudioContext suspenso...');
            await audioContextRef.current.resume();
            console.log('âœ… AudioContext resumido:', audioContextRef.current.state);
          } catch (error) {
            console.error('âŒ Erro ao resumir AudioContext:', error);
            throw new Error('NÃ£o foi possÃ­vel ativar o sistema de Ã¡udio');
          }
        }
        
        // Verificar se o AudioContext estÃ¡ funcionando
        if (audioContextRef.current.state !== 'running') {
          console.warn('âš ï¸ AudioContext nÃ£o estÃ¡ rodando:', audioContextRef.current.state);
          
          // Em dispositivos mÃ³veis, tentar uma abordagem diferente
          if (isMobileDevice()) {
            console.log('ðŸ“± Dispositivo mÃ³vel detectado, tentando abordagem alternativa...');
            try {
              // ForÃ§ar o contexto a funcionar
              await audioContextRef.current.resume();
              console.log('âœ… AudioContext forÃ§ado a funcionar:', audioContextRef.current.state);
              
              // Se ainda nÃ£o estiver rodando, tentar criar um oscilador temporÃ¡rio
              if (audioContextRef.current.state !== 'running') {
                console.log('ðŸ”„ Tentando ativar com oscilador temporÃ¡rio...');
                const tempOsc = audioContextRef.current.createOscillator();
                const tempGain = audioContextRef.current.createGain();
                tempGain.gain.setValueAtTime(0.001, 0); // Volume muito baixo
                tempOsc.connect(tempGain);
                tempGain.connect(audioContextRef.current.destination);
                tempOsc.start(0);
                tempOsc.stop(0.5);
                
                // Aguardar um pouco
                await new Promise(resolve => setTimeout(resolve, 100));
                console.log('âœ… Estado apÃ³s oscilador temporÃ¡rio:', audioContextRef.current.state);
              }
            } catch (forceError) {
              console.error('âŒ Falha ao forÃ§ar AudioContext:', forceError);
            }
          }
        }
        
        // VerificaÃ§Ã£o final
        if (audioContextRef.current.state === 'running') {
          console.log('ðŸŽµ AudioContext funcionando perfeitamente!');
        } else {
          console.warn('âš ï¸ AudioContext ainda nÃ£o estÃ¡ funcionando:', audioContextRef.current.state);
        }
      }, []);

      const stopAllNodes = React.useCallback((context = audioContextRef.current) => {
        if (!context) return;
        const nodesToStop = [osc1Ref.current, osc2Ref.current, pulseLFORef.current];
        nodesToStop.forEach(node => {
          if (node) { try { node.stop(); } catch(e){} try { node.disconnect(); } catch(e){} }
        });
        osc1Ref.current = null; osc2Ref.current = null; pulseLFORef.current = null;

        const nodesToDisconnect = [panner1Ref.current, panner2Ref.current, lfoModulatorGainRef.current, isochronicCarrierGainRef.current];
        nodesToDisconnect.forEach(node => { if (node) { try { node.disconnect(); } catch(e){} } });
        panner1Ref.current = null; panner2Ref.current = null; lfoModulatorGainRef.current = null; isochronicCarrierGainRef.current = null;

        if (context === audioContextRef.current) currentPlayingTypeRef.current = null;
      }, []);

      const createAudioGraph = React.useCallback((ac, destinationNode, type, settings, nodeRefs) => {
        // Clean existing refs
        Object.values(nodeRefs).forEach(ref => {
          if (ref.current) { try { ref.current.disconnect(); } catch(e){} ref.current = null; }
        });

        switch (type) {
          case ToneType.ISOCHRONIC: {
            const { carrierFreq, pulseFreq } = settings;
            nodeRefs.osc1Ref.current = ac.createOscillator();
            nodeRefs.osc1Ref.current.type = 'sine';
            nodeRefs.osc1Ref.current.frequency.setValueAtTime(carrierFreq, ac.currentTime);

            nodeRefs.isochronicCarrierGainRef.current = ac.createGain();
            nodeRefs.isochronicCarrierGainRef.current.gain.setValueAtTime(0.5, ac.currentTime);

            nodeRefs.pulseLFORef.current = ac.createOscillator();
            nodeRefs.pulseLFORef.current.type = 'sine';
            nodeRefs.pulseLFORef.current.frequency.setValueAtTime(pulseFreq, ac.currentTime);

            nodeRefs.lfoModulatorGainRef.current = ac.createGain();
            nodeRefs.lfoModulatorGainRef.current.gain.setValueAtTime(0.5, ac.currentTime);

            nodeRefs.osc1Ref.current.connect(nodeRefs.isochronicCarrierGainRef.current);
            nodeRefs.isochronicCarrierGainRef.current.connect(destinationNode);

            nodeRefs.pulseLFORef.current.connect(nodeRefs.lfoModulatorGainRef.current);
            nodeRefs.lfoModulatorGainRef.current.connect(nodeRefs.isochronicCarrierGainRef.current.gain);
            break;
          }
          case ToneType.BINAURAL: {
            const { baseFreq, beatFreq } = settings;
            const freqLeft = baseFreq - beatFreq / 2;
            const freqRight = baseFreq + beatFreq / 2;

            nodeRefs.osc1Ref.current = ac.createOscillator();
            nodeRefs.osc1Ref.current.type = 'sine';
            nodeRefs.osc1Ref.current.frequency.setValueAtTime(freqLeft, ac.currentTime);
            nodeRefs.panner1Ref.current = ac.createStereoPanner();
            nodeRefs.panner1Ref.current.pan.setValueAtTime(-1, ac.currentTime);
            nodeRefs.osc1Ref.current.connect(nodeRefs.panner1Ref.current).connect(destinationNode);

            nodeRefs.osc2Ref.current = ac.createOscillator();
            nodeRefs.osc2Ref.current.type = 'sine';
            nodeRefs.osc2Ref.current.frequency.setValueAtTime(freqRight, ac.currentTime);
            nodeRefs.panner2Ref.current = ac.createStereoPanner();
            nodeRefs.panner2Ref.current.pan.setValueAtTime(1, ac.currentTime);
            nodeRefs.osc2Ref.current.connect(nodeRefs.panner2Ref.current).connect(destinationNode);
            break;
          }
          case ToneType.MONAURAL: {
            const { freq1, freq2 } = settings;
            nodeRefs.osc1Ref.current = ac.createOscillator();
            nodeRefs.osc1Ref.current.type = 'sine';
            nodeRefs.osc1Ref.current.frequency.setValueAtTime(freq1, ac.currentTime);
            nodeRefs.osc1Ref.current.connect(destinationNode);

            nodeRefs.osc2Ref.current = ac.createOscillator();
            nodeRefs.osc2Ref.current.type = 'sine';
            nodeRefs.osc2Ref.current.frequency.setValueAtTime(freq2, ac.currentTime);
            nodeRefs.osc2Ref.current.connect(destinationNode);
            break;
          }
        }
      }, []);

            const play = React.useCallback(async (type, settings, globalVolume) => {
        try {
          await ensureAudioContext();
          const ac = audioContextRef.current;
          const masterGain = masterGainRef.current;
          if (!ac || !masterGain) {
            console.error('AudioContext ou MasterGain nÃ£o disponÃ­vel');
            return;
          }
          stopAllNodes();

          masterGain.gain.setValueAtTime(globalVolume, ac.currentTime);
          currentPlayingTypeRef.current = type;

          const liveNodeRefs = {
            osc1Ref, osc2Ref, panner1Ref, panner2Ref, isochronicCarrierGainRef, pulseLFORef, lfoModulatorGainRef
          };

          createAudioGraph(ac, masterGain, type, settings, liveNodeRefs);

          if (liveNodeRefs.osc1Ref.current) try{ liveNodeRefs.osc1Ref.current.start(ac.currentTime); }catch(e){}
          if (liveNodeRefs.osc2Ref.current) try{ liveNodeRefs.osc2Ref.current.start(ac.currentTime); }catch(e){}
          if (liveNodeRefs.pulseLFORef.current) try{ liveNodeRefs.pulseLFORef.current.start(ac.currentTime); }catch(e){}

          setIsPlaying(true);
        } catch (error) {
          console.error('âŒ Erro ao reproduzir Ã¡udio:', error);
          
          // Em dispositivos mÃ³veis, mostrar mensagem especÃ­fica
          if (isMobileDevice()) {
            console.log('ðŸ“± Erro em dispositivo mÃ³vel:', error.message);
            
            if (error.message.includes('sistema de Ã¡udio')) {
              alert('âŒ Sistema de Ã¡udio nÃ£o ativado!\n\nðŸ“± Para dispositivos mÃ³veis:\n1. Clique no botÃ£o "ðŸ”Š Ativar Sistema de Ãudio"\n2. Aguarde a confirmaÃ§Ã£o\n3. Tente reproduzir novamente\n\nðŸ’¡ Dica: Em iOS, pode ser necessÃ¡rio tocar na tela primeiro');
            } else if (error.message.includes('Web Audio API')) {
              alert('âŒ Web Audio API nÃ£o suportada!\n\nðŸ“± Este navegador nÃ£o suporta reproduÃ§Ã£o de Ã¡udio.\n\nðŸ”§ Tente usar:\nâ€¢ Chrome (Android)\nâ€¢ Safari (iOS)\nâ€¢ Firefox (Android)');
            } else {
              alert('âŒ Erro ao reproduzir Ã¡udio no celular!\n\nðŸ”§ SoluÃ§Ãµes:\nâ€¢ Verifique se o volume estÃ¡ ligado\nâ€¢ Tente ativar o sistema de Ã¡udio novamente\nâ€¢ Recarregue a pÃ¡gina se necessÃ¡rio\nâ€¢ Verifique as permissÃµes do navegador');
            }
          } else {
            alert('âŒ Erro ao reproduzir Ã¡udio: ' + error.message);
          }
        }
      }, [ensureAudioContext, stopAllNodes, createAudioGraph]);

      const stop = React.useCallback(() => { stopAllNodes(); setIsPlaying(false); }, [stopAllNodes]);

      const setGlobalVolume = React.useCallback((volume) => {
        if (masterGainRef.current && audioContextRef.current) {
          masterGainRef.current.gain.setValueAtTime(volume, audioContextRef.current.currentTime);
        }
      }, []);

      React.useEffect(() => {
        const ac = audioContextRef.current;
        return () => {
          stopAllNodes();
          if (ac && ac.state !== 'closed') {
            ac.close().catch(()=>{});
            audioContextRef.current = null;
            masterGainRef.current = null;
          }
        };
      }, [stopAllNodes]);

      // WAV encoding helpers
      function interleave(inputL, inputR) {
        const length = inputL.length + inputR.length;
        const result = new Float32Array(length);
        let index = 0, inputIndex = 0;
        while (index < length) {
          result[index++] = inputL[inputIndex];
          result[index++] = inputR[inputIndex];
          inputIndex++;
        }
        return result;
      }

      function encodeWAV(audioBuffer) {
        const numChannels = audioBuffer.numberOfChannels;
        const sampleRate = audioBuffer.sampleRate;
        const bitDepth = 16;
        let result;
        if (numChannels === 2) result = interleave(audioBuffer.getChannelData(0), audioBuffer.getChannelData(1));
        else result = audioBuffer.getChannelData(0);

        const dataLength = result.length * (bitDepth / 8);
        const buffer = new ArrayBuffer(44 + dataLength);
        const view = new DataView(buffer);
        let offset = 0;

        function writeString(str) { for (let i=0;i<str.length;i++) view.setUint8(offset++, str.charCodeAt(i)); }

        writeString('RIFF');
        view.setUint32(offset, 36 + dataLength, true); offset += 4;
        writeString('WAVE');
        writeString('fmt ');
        view.setUint32(offset, 16, true); offset += 4;
        view.setUint16(offset, 1, true); offset += 2; // PCM
        view.setUint16(offset, numChannels, true); offset += 2;
        view.setUint32(offset, sampleRate, true); offset += 4;
        view.setUint32(offset, sampleRate * numChannels * (bitDepth/8), true); offset += 4;
        view.setUint16(offset, numChannels * (bitDepth/8), true); offset += 2;
        view.setUint16(offset, bitDepth, true); offset += 2;
        writeString('data');
        view.setUint32(offset, dataLength, true); offset += 4;

        let index = 0;
        while (offset < 44 + dataLength && index < result.length) {
          let sample = result[index++];
          sample = Math.max(-1, Math.min(1, sample));
          sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
          view.setInt16(offset, sample, true);
          offset += 2;
        }
        return new Blob([view], { type: 'audio/wav' });
      }

      const exportAudioAsWav = async (type, settings, globalVolume, durationInSeconds) => {
        const sampleRate = 44100;
        const numChannels = (type === ToneType.BINAURAL) ? 2 : 1;
        const OfflineAC = window.OfflineAudioContext || window.webkitOfflineAudioContext;
        if (!OfflineAC) throw new Error("OfflineAudioContext nÃ£o suportado no navegador.");

        const offlineCtx = new OfflineAC(numChannels, Math.floor(sampleRate * durationInSeconds), sampleRate);
        const offlineMasterGain = offlineCtx.createGain();
        offlineMasterGain.gain.setValueAtTime(globalVolume, 0);
        offlineMasterGain.connect(offlineCtx.destination);

        const offlineNodeRefs = {
          osc1Ref: { current: null },
          osc2Ref: { current: null },
          panner1Ref: { current: null },
          panner2Ref: { current: null },
          isochronicCarrierGainRef: { current: null },
          pulseLFORef: { current: null },
          lfoModulatorGainRef: { current: null }
        };

        createAudioGraph(offlineCtx, offlineMasterGain, type, settings, offlineNodeRefs);

        if (offlineNodeRefs.osc1Ref.current) try{ offlineNodeRefs.osc1Ref.current.start(0); }catch(e){}
        if (offlineNodeRefs.osc2Ref.current) try{ offlineNodeRefs.osc2Ref.current.start(0); }catch(e){}
        if (offlineNodeRefs.pulseLFORef.current) try{ offlineNodeRefs.pulseLFORef.current.start(0); }catch(e){}

        const rendered = await offlineCtx.startRendering();
        if (!rendered || rendered.length === 0) throw new Error("Render vazio.");
        const wavBlob = encodeWAV(rendered);

        const url = URL.createObjectURL(wavBlob);
        const a = document.createElement('a');
        document.body.appendChild(a);
        a.style.display = 'none';
        a.href = url;
        const timestamp = new Date().toISOString().replace(/[:.]/g,'-');
        a.download = `aura_harmonics_${type.toLowerCase().replace(/\s+/g,'_')}_${timestamp}.wav`;
        a.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(a);
        return true;
      };

      return { play, stop, isPlaying, setGlobalVolume, exportAudioAsWav };
    }

    /************ ControlPanel Component ************/
    function ControlPanel(props) {
      const {
        toneTypesConfig, selectedToneType, onToneTypeChange, settings, onSettingsChange,
        volume, onVolumeChange, onPlayToggle, isPlaying, onExport, exportDuration, onExportDurationChange,
        isExporting, exportStatusMessage, presets, onPresetSelect
      } = props;

      const [isInfoExpanded, setIsInfoExpanded] = React.useState(false);

      const renderSettingsInputs = () => {
        if (selectedToneType === ToneType.ISOCHRONIC) {
          return React.createElement(React.Fragment, null,
            React.createElement(ParameterInput, { 
              label:"FrequÃªncia Portadora (Hz)", 
              id:"carrierFreq", 
              value: settings.carrierFreq, 
              onChange: v => onSettingsChange({carrierFreq: v}), 
              min: FREQUENCY_RANGES.carrierFreq.min, 
              max: FREQUENCY_RANGES.carrierFreq.max, 
              step: FREQUENCY_RANGES.carrierFreq.step,
              tooltip: "FrequÃªncia principal do tom isocrÃ´nico. Esta Ã© a frequÃªncia base que serÃ¡ pulsada para criar o efeito de sincronizaÃ§Ã£o cerebral."
            }),
            React.createElement(ParameterInput, { 
              label:"FrequÃªncia de Pulso (Hz)", 
              id:"pulseFreq", 
              value: settings.pulseFreq, 
              onChange: v => onSettingsChange({pulseFreq: v}), 
              min: FREQUENCY_RANGES.pulseFreq.min, 
              max: FREQUENCY_RANGES.pulseFreq.max, 
              step: FREQUENCY_RANGES.pulseFreq.step,
              tooltip: "Velocidade com que o tom portador Ã© ligado e desligado. FrequÃªncias baixas (0.5-10Hz) sÃ£o ideais para relaxamento, altas (10-40Hz) para foco."
            })
          );
        } else if (selectedToneType === ToneType.BINAURAL) {
          return React.createElement(React.Fragment, null,
            React.createElement(ParameterInput, { 
              label:"FrequÃªncia Base (Hz)", 
              id:"baseFreq", 
              value: settings.baseFreq, 
              onChange: v => onSettingsChange({baseFreq: v}), 
              min: FREQUENCY_RANGES.baseFreq.min, 
              max: FREQUENCY_RANGES.baseFreq.max, 
              step: FREQUENCY_RANGES.baseFreq.step,
              tooltip: "FrequÃªncia central das batidas binaurais. O cÃ©rebro criarÃ¡ batidas na diferenÃ§a entre as frequÃªncias dos dois ouvidos."
            }),
            React.createElement(ParameterInput, { 
              label:"FrequÃªncia de Batida (Hz)", 
              id:"beatFreq", 
              value: settings.beatFreq, 
              onChange: v => onSettingsChange({beatFreq: v}), 
              min: FREQUENCY_RANGES.beatFreq.min, 
              max: FREQUENCY_RANGES.beatFreq.max, 
              step: FREQUENCY_RANGES.beatFreq.step,
              tooltip: "FrequÃªncia da batida percebida pelo cÃ©rebro. Delta (0.5-4Hz): sono profundo, Theta (4-8Hz): meditaÃ§Ã£o, Alpha (8-13Hz): relaxamento, Beta (13-30Hz): foco."
            })
          );
        } else {
          return React.createElement(React.Fragment, null,
            React.createElement(ParameterInput, { 
              label:"FrequÃªncia 1 (Hz)", 
              id:"freq1", 
              value: settings.freq1, 
              onChange: v => onSettingsChange({freq1: v}), 
              min: FREQUENCY_RANGES.freq1.min, 
              max: FREQUENCY_RANGES.freq1.max, 
              step: FREQUENCY_RANGES.freq1.step,
              tooltip: "Primeira frequÃªncia para criar batidas monaurais. Esta frequÃªncia serÃ¡ misturada com a segunda para criar o efeito desejado."
            }),
            React.createElement(ParameterInput, { 
              label:"FrequÃªncia 2 (Hz)", 
              id:"freq2", 
              value: settings.freq2, 
              onChange: v => onSettingsChange({freq2: v}), 
              min: FREQUENCY_RANGES.freq2.min, 
              max: FREQUENCY_RANGES.freq2.max, 
              step: FREQUENCY_RANGES.freq2.step,
              tooltip: "Segunda frequÃªncia para criar batidas monaurais. A diferenÃ§a entre as duas frequÃªncias determina o efeito percebido."
            })
          );
        }
      };

      return (
        React.createElement("div", { className: "space-y-6" },
          React.createElement("div", { className: "p-1 bg-gray-700 rounded-lg flex space-x-1" },
            toneTypesConfig.map(tone => {
              let tooltipText = "";
              switch (tone.id) {
                case ToneType.ISOCHRONIC:
                  tooltipText = "Tons isocrÃ´nicos sÃ£o pulsos de som que se ligam e desligam em uma frequÃªncia especÃ­fica. Eles podem ajudar na sincronizaÃ§Ã£o das ondas cerebrais para foco, relaxamento e meditaÃ§Ã£o.";
                  break;
                case ToneType.BINAURAL:
                  tooltipText = "Batidas binaurais sÃ£o criadas quando dois tons de frequÃªncias ligeiramente diferentes sÃ£o apresentados separadamente para cada ouvido. O cÃ©rebro percebe a diferenÃ§a como uma batida rÃ­tmica que pode influenciar estados mentais.";
                  break;
                case ToneType.MONAURAL:
                  tooltipText = "Batidas monaurais sÃ£o criadas quando dois tons de frequÃªncias diferentes sÃ£o misturados antes de chegarem aos ouvidos. Eles podem ajudar na concentraÃ§Ã£o e relaxamento.";
                  break;
              }
              return React.createElement("button", {
                key: tone.id,
                onClick: () => onToneTypeChange(tone.id),
                disabled: isPlaying || isExporting,
                title: tooltipText,
                className: `w-full py-2.5 px-4 rounded-md text-sm font-medium transition-colors duration-150 focus:outline-none ${selectedToneType === tone.id ? 'bg-violet-600 text-white shadow-md' : 'text-gray-300 hover:bg-gray-600 hover:text-white'} disabled:opacity-60 disabled:cursor-not-allowed`
              }, tone.label);
            })
          ),

          React.createElement("div", { className: "p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("h3", { className: "text-lg font-medium text-gray-200 mb-3" }, "Presets"),
            React.createElement("div", { className: "grid grid-cols-2 sm:grid-cols-3 gap-2" },
              presets.map(p => {
                let detailedTooltip = "";
                switch (p.id) {
                  case 'focusAlphaBinaural':
                    detailedTooltip = "Foco (Alpha Binaural): FrequÃªncia de 10Hz para clareza mental e concentraÃ§Ã£o. Ideal para estudos, trabalho e atividades que requerem atenÃ§Ã£o.";
                    break;
                  case 'meditationThetaBinaural':
                    detailedTooltip = "MeditaÃ§Ã£o (Theta Binaural): FrequÃªncia de 6Hz para relaxamento profundo e meditaÃ§Ã£o. Ajuda a alcanÃ§ar estados de consciÃªncia alterados.";
                    break;
                  case 'solfeggio528Iso':
                    detailedTooltip = "Solfeggio 528Hz (Iso): FrequÃªncia conhecida como 'frequÃªncia do amor'. Promove equilÃ­brio emocional, transformaÃ§Ã£o e cura.";
                    break;
                  case 'solfeggio396Monaural':
                    detailedTooltip = "Solfeggio 396Hz (Mon): FrequÃªncia para liberaÃ§Ã£o de medos e culpas. Ajuda a limpar bloqueios emocionais e traumas.";
                    break;
                  case 'astralProjectionThetaIso':
                    detailedTooltip = "ProjeÃ§Ã£o Astral (Theta Iso): FrequÃªncia de 4.5Hz para estados alterados de consciÃªncia e experiÃªncias transcendentais.";
                    break;
                  case 'healingGeneralIso':
                    detailedTooltip = "Cura Geral (432Hz Iso): FrequÃªncia harmonizadora que promove equilÃ­brio fÃ­sico, mental e espiritual.";
                    break;
                }
                return React.createElement("button", {
                  key: p.id, onClick: () => onPresetSelect(p.id), disabled: isExporting,
                  title: detailedTooltip,
                  className: "px-3 py-2 text-xs font-medium text-center text-white bg-violet-500 rounded-lg hover:bg-violet-600 focus:outline-none disabled:opacity-50 disabled:cursor-not-allowed truncate"
                }, p.name);
              })
            )
          ),

          React.createElement("div", { className: "grid grid-cols-1 md:grid-cols-2 gap-x-6 gap-y-4 p-4 bg-gray-700/50 rounded-lg" }, renderSettingsInputs()),

          React.createElement("div", { className: "p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("label", { 
              htmlFor:"volume", 
              className:"block text-sm font-medium text-gray-300 mb-1",
              title: "Controla o volume geral de todos os sons gerados. Ajuste conforme sua preferÃªncia e ambiente de uso."
            }, "Volume Principal"),
            React.createElement("div", { className:"flex items-center space-x-3" },
              React.createElement("input", {
                id:"volume", type:"range", min:0, max:1, step:0.01, value: volume,
                onChange: e => onVolumeChange(parseFloat(e.target.value)),
                disabled: isExporting,
                className: "w-full h-2 bg-gray-600 rounded-lg appearance-none cursor-pointer"
              }),
              React.createElement("span", { className: "text-sm text-gray-400 w-12 text-right" }, `${(volume*100).toFixed(0)}%`)
            )
          ),

          React.createElement("div", { className: "flex justify-center items-center space-x-4 pt-4" },
            React.createElement("button", {
              onClick: onPlayToggle, disabled: isExporting,
              "aria-label": isPlaying ? 'Pausar' : 'Reproduzir',
              title: isPlaying ? "Clique para pausar a reproduÃ§Ã£o do Ã¡udio atual" : "Clique para iniciar a reproduÃ§Ã£o do Ã¡udio com as configuraÃ§Ãµes selecionadas",
              className: `p-4 rounded-full transition-all duration-150 focus:outline-none ${isPlaying ? 'bg-teal-500 text-white' : 'bg-green-500 text-white'} disabled:opacity-60 disabled:cursor-not-allowed`
            }, isPlaying ? "Pausar" : "Reproduzir"),
            React.createElement("button", {
              onClick: () => { if (isPlaying) onPlayToggle(); }, disabled: !isPlaying || isExporting,
              title: "Clique para parar completamente a reproduÃ§Ã£o do Ã¡udio e retornar ao estado inicial",
              className: "p-4 bg-red-500 text-white rounded-full transition-all duration-150 hover:bg-red-600 focus:outline-none disabled:opacity-50 disabled:cursor-not-allowed"
            }, "Parar")
          ),

          React.createElement("div", { className: "mt-6 pt-6 border-t border-gray-700 space-y-4 p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("h3", { className: "text-lg font-medium text-gray-200" }, "Exportar Ãudio"),
            React.createElement(ParameterInput, { 
              label:"DuraÃ§Ã£o (minutos)", 
              id:"exportDuration", 
              value: exportDuration, 
              onChange: onExportDurationChange, 
              min: MIN_EXPORT_DURATION_MINUTES, 
              max: MAX_EXPORT_DURATION_MINUTES, 
              step:1, 
              unit:"min",
              tooltip: "Define a duraÃ§Ã£o do arquivo de Ã¡udio exportado. Arquivos mais longos levam mais tempo para processar, mas permitem sessÃµes mais extensas."
            }),
            React.createElement("button", {
              onClick: onExport, disabled: isPlaying || isExporting,
              title: "Exporta o Ã¡udio atual como arquivo WAV para download. O arquivo serÃ¡ salvo com a duraÃ§Ã£o especificada e as configuraÃ§Ãµes atuais de frequÃªncia e volume.",
              className: "w-full py-2.5 px-4 rounded-md text-sm font-medium bg-emerald-600 hover:bg-emerald-700 text-white focus:outline-none disabled:opacity-50 disabled:cursor-not-allowed"
            }, isExporting ? "Exportando..." : "Exportar como WAV"),
            React.createElement("p", { className: "text-xs text-gray-400 text-center export-status" }, exportStatusMessage)
          ),

          React.createElement("div", { className: "mt-6 pt-6 border-t border-gray-700 p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("button", {
              onClick: () => setIsInfoExpanded(!isInfoExpanded),
              className: "w-full text-left text-lg font-medium text-gray-200 hover:text-violet-400 transition-colors flex justify-between items-center",
              "aria-expanded": isInfoExpanded,
              title: "Clique para expandir/recolher informaÃ§Ãµes sobre frequÃªncias sonoras especÃ­ficas e seus efeitos terapÃªuticos conhecidos"
            }, "InformaÃ§Ãµes sobre FrequÃªncias Sonoras",
              React.createElement("svg", { className: `w-5 h-5 transform ${isInfoExpanded ? 'rotate-180' : 'rotate-0'}`, fill:"none", stroke:"currentColor", viewBox:"0 0 24 24" },
                React.createElement("path", { strokeLinecap:"round", strokeLinejoin:"round", strokeWidth:"2", d:"M19 9l-7 7-7-7" })
              )
            ),
            isInfoExpanded && React.createElement("div", { className: "mt-3 text-xs text-gray-400 space-y-2" },
              React.createElement("p", null, "As frequÃªncias sonoras (Hz) tÃªm usos em Ã¡udio e terapias sonoras; use com responsabilidade."),
              React.createElement("ul", { className: "list-disc list-inside pl-2" },
                React.createElement("li", null, React.createElement("strong", null, "174 Hz:"), " AlÃ­vio de estresse."),
                React.createElement("li", null, React.createElement("strong", null, "396 Hz:"), " LiberaÃ§Ã£o de medo."),
                React.createElement("li", null, React.createElement("strong", null, "528 Hz:"), " TransformaÃ§Ã£o emocional.")
              )
            )
          )
        )
      );
    }

    /************ App Component ************/
    function App() {
      const [selectedToneType, setSelectedToneType] = React.useState(ToneType.ISOCHRONIC);
      const [isochronicSettings, setIsochronicSettings] = React.useState(DEFAULT_ISOCHRONIC_SETTINGS);
      const [binauralSettings, setBinauralSettings] = React.useState(DEFAULT_BINAURAL_SETTINGS);
      const [monauralSettings, setMonauralSettings] = React.useState(DEFAULT_MONAURAL_SETTINGS);
      const [volume, setVolume] = React.useState(DEFAULT_VOLUME);
      const [audioContextActivated, setAudioContextActivated] = React.useState(false);

      const [exportDuration, setExportDuration] = React.useState(DEFAULT_EXPORT_DURATION_MINUTES);
      const [isExporting, setIsExporting] = React.useState(false);
      const [exportStatusMessage, setExportStatusMessage] = React.useState("");

      const audio = useAudioEngine();
      const { play, stop, isPlaying, setGlobalVolume, exportAudioAsWav } = audio;

      // Verificar se Ã© dispositivo mÃ³vel e mostrar instruÃ§Ãµes
      React.useEffect(() => {
        if (isMobileDevice()) {
          console.log('ðŸ“± Dispositivo mÃ³vel detectado');
          console.log('User Agent:', navigator.userAgent);
          console.log('Touch Points:', navigator.maxTouchPoints);
          console.log('Largura da tela:', window.innerWidth);
          console.log('ðŸŽ iOS:', isIOS() ? 'Sim' : 'NÃ£o');
          console.log('ðŸ¤– Android:', isAndroid() ? 'Sim' : 'NÃ£o');
          console.log('ðŸŒ Navegador:', navigator.userAgent.includes('Chrome') ? 'Chrome' : 
                                    navigator.userAgent.includes('Safari') ? 'Safari' : 
                                    navigator.userAgent.includes('Firefox') ? 'Firefox' : 'Outro');
          
          // Verificar suporte Ã  Web Audio API
          if (!window.AudioContext && !window.webkitAudioContext) {
            console.error('âŒ Web Audio API nÃ£o suportada!');
            alert('âŒ Seu navegador nÃ£o suporta reproduÃ§Ã£o de Ã¡udio!\n\nðŸ“± Use Chrome (Android) ou Safari (iOS)');
          } else {
            console.log('âœ… Web Audio API suportada');
          }
          
          // Mostrar instruÃ§Ãµes especÃ­ficas para mÃ³veis
          setTimeout(() => {
            if (!audioContextActivated) {
              console.log('ðŸ’¡ Mostrando instruÃ§Ãµes para dispositivo mÃ³vel');
            }
          }, 1000);
        }
      }, [audioContextActivated]);

      // FunÃ§Ã£o para ativar o AudioContext em dispositivos mÃ³veis
      const activateAudioContext = React.useCallback(async () => {
        if (isMobileDevice() && !audioContextActivated) {
          try {
            console.log('ðŸš€ Tentando ativar AudioContext para dispositivo mÃ³vel...');
            console.log('ðŸ“± Tipo de dispositivo:', isIOS() ? 'iOS' : isAndroid() ? 'Android' : 'MÃ³vel GenÃ©rico');
            
            // Criar um AudioContext temporÃ¡rio para ativar o sistema
            const AudioContextClass = window.AudioContext || window.webkitAudioContext;
            if (!AudioContextClass) {
              throw new Error('Web Audio API nÃ£o suportada');
            }
            
            const tempContext = new AudioContextClass();
            console.log('âœ… AudioContext temporÃ¡rio criado, estado:', tempContext.state);
            
            // Tentar resumir o contexto
            if (tempContext.state === 'suspended') {
              console.log('ðŸ”„ Resumindo contexto suspenso...');
              await tempContext.resume();
              console.log('âœ… AudioContext temporÃ¡rio resumido, estado:', tempContext.state);
            }
            
            // Criar um oscilador temporÃ¡rio para "despertar" o sistema
            console.log('ðŸŽµ Criando oscilador temporÃ¡rio...');
            const tempOsc = tempContext.createOscillator();
            const tempGain = tempContext.createGain();
            
            // Volume muito baixo mas nÃ£o zero (iOS pode nÃ£o processar volume 0)
            tempGain.gain.setValueAtTime(0.001, 0);
            tempOsc.frequency.setValueAtTime(440, 0); // Nota A4
            
            tempOsc.connect(tempGain);
            tempGain.connect(tempContext.destination);
            
            // Executar por mais tempo para garantir processamento
            tempOsc.start(0);
            tempOsc.stop(0.5);
            
            // Aguardar o processamento
            await new Promise(resolve => setTimeout(resolve, 600));
            
            console.log('âœ… Estado final do contexto temporÃ¡rio:', tempContext.state);
            
            // Fechar o contexto temporÃ¡rio
            tempContext.close();
            console.log('ðŸ”’ Contexto temporÃ¡rio fechado');
            
            setAudioContextActivated(true);
            console.log('âœ… AudioContext ativado com sucesso para dispositivo mÃ³vel');
            
            // Mostrar mensagem de sucesso
            alert('âœ… Sistema de Ã¡udio ativado!\n\nðŸŽµ Agora vocÃª pode reproduzir sons.\n\nðŸ’¡ Dica: Se ainda nÃ£o funcionar, tente aumentar o volume do dispositivo.');
            
          } catch (error) {
            console.error('âŒ Erro ao ativar AudioContext:', error);
            alert('âŒ Erro ao ativar Ã¡udio: ' + error.message + '\n\nðŸ”§ Tente recarregar a pÃ¡gina ou verificar as permissÃµes do navegador.');
          }
        }
      }, [audioContextActivated]);

      const getCurrentSettings = React.useCallback(() => {
        switch (selectedToneType) {
          case ToneType.ISOCHRONIC: return isochronicSettings;
          case ToneType.BINAURAL: return binauralSettings;
          case ToneType.MONAURAL: return monauralSettings;
          default: return DEFAULT_ISOCHRONIC_SETTINGS;
        }
      }, [selectedToneType, isochronicSettings, binauralSettings, monauralSettings]);

      const handlePlayToggle = React.useCallback(() => {
        if (isExporting) return;
        if (isPlaying) stop();
        else play(selectedToneType, getCurrentSettings(), volume);
      }, [isPlaying, play, stop, selectedToneType, getCurrentSettings, volume, isExporting]);

      React.useEffect(() => {
        if (isPlaying && !isExporting) {
          play(selectedToneType, getCurrentSettings(), volume);
        }
        // eslint-disable-next-line
      }, [selectedToneType, isochronicSettings, binauralSettings, monauralSettings, volume]);

      React.useEffect(() => { return () => { if (isPlaying) stop(); }; }, [stop, isPlaying]);

      const updateSettings = (newSettings) => {
        if (isExporting) return;
        switch (selectedToneType) {
          case ToneType.ISOCHRONIC: setIsochronicSettings(prev => ({...prev, ...newSettings})); break;
          case ToneType.BINAURAL: setBinauralSettings(prev => ({...prev, ...newSettings})); break;
          case ToneType.MONAURAL: setMonauralSettings(prev => ({...prev, ...newSettings})); break;
        }
      };

      const handleToneTypeChange = (type) => { if (isPlaying || isExporting) return; setSelectedToneType(type); };

      const handleVolumeChange = (vol) => { if (isExporting) return; setVolume(vol); setGlobalVolume(vol); };

      const handleExportDurationChange = (dur) => {
        if (isExporting) return;
        let newDur = Math.max(MIN_EXPORT_DURATION_MINUTES, Math.min(dur, MAX_EXPORT_DURATION_MINUTES));
        if (isNaN(newDur) || !isFinite(newDur)) newDur = DEFAULT_EXPORT_DURATION_MINUTES;
        setExportDuration(newDur);
      };

      const handleExport = React.useCallback(async () => {
        if (isExporting || isPlaying) {
          setExportStatusMessage(isPlaying ? "Pare a reproduÃ§Ã£o antes de exportar." : "ExportaÃ§Ã£o jÃ¡ em andamento.");
          return;
        }

        setIsExporting(true);
        setExportStatusMessage("Inicializando exportaÃ§Ã£o...");
        try {
          setExportStatusMessage("Renderizando Ã¡udio... Aguarde.");
          await exportAudioAsWav(selectedToneType, getCurrentSettings(), volume, exportDuration * 60);
          setExportStatusMessage("ExportaÃ§Ã£o concluÃ­da! Verifique seus downloads.");
        } catch (err) {
          console.error("Export failed:", err);
          setExportStatusMessage(`Falha na exportaÃ§Ã£o: ${err.message || 'Erro desconhecido'}`);
        } finally {
          setIsExporting(false);
          setTimeout(()=>setExportStatusMessage(""), 7000);
        }
      }, [isExporting, isPlaying, exportAudioAsWav, selectedToneType, getCurrentSettings, volume, exportDuration]);

      const handlePresetSelect = React.useCallback((presetId) => {
        if (isExporting) return;
        const preset = PRESETS.find(p => p.id === presetId);
        if (!preset) return;
        setSelectedToneType(preset.toneType);
        switch (preset.toneType) {
          case ToneType.ISOCHRONIC: setIsochronicSettings(preset.settings); break;
          case ToneType.BINAURAL: setBinauralSettings(preset.settings); break;
          case ToneType.MONAURAL: setMonauralSettings(preset.settings); break;
        }
      }, [isExporting]);

      return (
        React.createElement("div", { 
          className: "min-h-screen bg-gray-900 text-gray-100 flex flex-col items-center justify-center p-4",
          onTouchStart: activateAudioContext,
          onClick: activateAudioContext,
          onTouchMove: activateAudioContext,
          onTouchEnd: activateAudioContext
        },
          React.createElement("div", { className: "w-full max-w-2xl bg-gray-800 shadow-2xl rounded-xl p-6 md:p-8" },
            React.createElement("header", { className: "mb-8 text-center" },
              React.createElement("h1", { className: "text-4xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-violet-400 to-fuchsia-500" }, "Aura Harmonics"),
              React.createElement("p", { className: "text-gray-400 mt-2" }, "Crie sua experiÃªncia auditiva para foco, relaxamento ou meditaÃ§Ã£o."),
              isMobileDevice() && React.createElement("div", { 
                className: `mt-4 p-3 border rounded-lg text-sm transition-colors duration-300 ${
                  audioContextActivated 
                    ? 'bg-green-900/30 border-green-500/30 text-green-200' 
                    : 'bg-blue-900/30 border-blue-500/30 text-blue-200'
                }` 
              }, 
                React.createElement("p", { className: "font-medium mb-1" }, 
                  audioContextActivated ? "âœ… Ãudio Ativado" : "ðŸ“± Dispositivo MÃ³vel Detectado"
                ),
                React.createElement("p", { className: "mb-3" }, 
                  audioContextActivated 
                    ? "O sistema de Ã¡udio estÃ¡ ativo! VocÃª pode reproduzir sons agora." 
                    : "Para reproduzir Ã¡udio, clique no botÃ£o abaixo para ativar o sistema."
                ),
                !audioContextActivated && React.createElement("div", { className: "space-y-2" },
                  React.createElement("button", {
                    onClick: activateAudioContext,
                    className: "w-full py-2 px-4 bg-blue-600 hover:bg-blue-700 text-white rounded-md font-medium transition-colors",
                    title: "Clique para ativar o sistema de Ã¡udio no seu dispositivo mÃ³vel"
                  }, "ðŸ”Š Ativar Sistema de Ãudio"),
                  React.createElement("button", {
                    onClick: () => {
                      console.log('ðŸ§ª Testando Ã¡udio...');
                      const testContext = new (window.AudioContext || window.webkitAudioContext)();
                      const testOsc = testContext.createOscillator();
                      const testGain = testContext.createGain();
                      testGain.gain.setValueAtTime(0.1, 0);
                      testOsc.frequency.setValueAtTime(440, 0);
                      testOsc.connect(testGain);
                      testGain.connect(testContext.destination);
                      testOsc.start(0);
                      testOsc.stop(0.3);
                      setTimeout(() => testContext.close(), 400);
                      alert('ðŸ§ª Teste de Ã¡udio executado! Se vocÃª ouviu um beep, o Ã¡udio estÃ¡ funcionando.');
                    },
                    className: "w-full py-2 px-4 bg-green-600 hover:bg-green-700 text-white rounded-md font-medium transition-colors text-sm",
                    title: "Testa se o Ã¡udio estÃ¡ funcionando no seu dispositivo"
                  }, "ðŸ§ª Testar Ãudio")
                )
              )
            ),
            React.createElement("main", null,
              React.createElement(ControlPanel, {
                toneTypesConfig: TONE_TYPES_CONFIG,
                selectedToneType,
                onToneTypeChange: handleToneTypeChange,
                settings: getCurrentSettings(),
                onSettingsChange: updateSettings,
                volume,
                onVolumeChange: handleVolumeChange,
                onPlayToggle: handlePlayToggle,
                isPlaying,
                onExport: handleExport,
                exportDuration,
                onExportDurationChange: handleExportDurationChange,
                isExporting,
                exportStatusMessage,
                presets: PRESETS,
                onPresetSelect: handlePresetSelect
              })
            ),
            React.createElement("footer", { className: "mt-8 text-center text-gray-500 text-sm" },
              React.createElement("p", null, `Â© ${new Date().getFullYear()} Aura Harmonics. Todos os direitos reservados.`),
              React.createElement("p", { className: "mt-1" }, "Experimente com responsabilidade. NÃ£o Ã© um dispositivo mÃ©dico.")
            )
          )
        )
      );
    }

    /************ Mount App ************/
    const rootEl = document.getElementById('root');
    const root = createRoot(rootEl);
    root.render(React.createElement(React.StrictMode, null, React.createElement(App, null)));
  </script>
</body>
</html>

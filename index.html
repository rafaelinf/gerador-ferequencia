<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Aura Harmonics - Gerador de Tons</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body { font-family: Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial; background:#111827; color:#f3f4f6; }
    ::-webkit-scrollbar { width:8px; }
    ::-webkit-scrollbar-track { background:#1f2937; }
    ::-webkit-scrollbar-thumb { background:#4b5563; border-radius:4px; }
    ::-webkit-scrollbar-thumb:hover { background:#6b7280; }
    .export-status { min-height: 1.5em; }
  </style>
</head>
<body class="antialiased">
  <div id="root"></div>

  <!-- Usamos m√≥dulos ESM para React/ReactDOM (esm.sh CDN) -->
  <script type="module">
    import React from "https://esm.sh/react@18.2.0";
    import { createRoot } from "https://esm.sh/react-dom@18.2.0/client";

    /************ Constants & Types ************/
    const ToneType = {
      ISOCHRONIC: "Isochronic",
      BINAURAL: "Binaural",
      MONAURAL: "Monaural"
    };

          // Fun√ß√£o para detectar dispositivos m√≥veis
      const isMobileDevice = () => {
        return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) ||
               (navigator.maxTouchPoints && navigator.maxTouchPoints > 2) ||
               window.innerWidth <= 768;
      };

    const DEFAULT_VOLUME = 0.5;
    const DEFAULT_ISOCHRONIC_SETTINGS = { carrierFreq: 136.1, pulseFreq: 7.83 };
    const DEFAULT_BINAURAL_SETTINGS = { baseFreq: 100, beatFreq: 10 };
    const DEFAULT_MONAURAL_SETTINGS = { freq1: 200, freq2: 205 };
    const FREQUENCY_RANGES = {
      carrierFreq: { min: 20, max: 1500, step: 0.1 },
      pulseFreq:   { min: 0.5, max: 40, step: 0.1 },
      baseFreq:    { min: 20, max: 1500, step: 0.1 },
      beatFreq:    { min: 0.5, max: 50, step: 0.1 },
      freq1:       { min: 20, max: 1500, step: 0.1 },
      freq2:       { min: 20, max: 1500, step: 0.1 }
    };

    const TONE_TYPES_CONFIG = [
      { id: ToneType.ISOCHRONIC, label: 'Tons Isocr√¥nicos' },
      { id: ToneType.BINAURAL, label: 'Batidas Binaurais' },
      { id: ToneType.MONAURAL, label: 'Batidas Monaurais' }
    ];

    const DEFAULT_EXPORT_DURATION_MINUTES = 5;
    const MIN_EXPORT_DURATION_MINUTES = 1;
    const MAX_EXPORT_DURATION_MINUTES = 120;

    const PRESETS = [
      { id:'focusAlphaBinaural', name:"Foco (Alpha Binaural)", description:"Para clareza mental", toneType: ToneType.BINAURAL, settings:{ baseFreq:100, beatFreq:10 } },
      { id:'meditationThetaBinaural', name:"Medita√ß√£o (Theta Binaural)", description:"Relaxamento profundo", toneType: ToneType.BINAURAL, settings:{ baseFreq:136.1, beatFreq:6 } },
      { id:'solfeggio528Iso', name:"Solfeggio 528Hz (Iso)", description:"Equil√≠brio emocional", toneType: ToneType.ISOCHRONIC, settings:{ carrierFreq:528, pulseFreq:7.83 } },
      { id:'solfeggio396Monaural', name:"Solfeggio 396Hz (Mon)", description:"Libera√ß√£o de medos", toneType: ToneType.MONAURAL, settings:{ freq1:396, freq2:398 } },
      { id:'astralProjectionThetaIso', name:"Proje√ß√£o Astral (Theta Iso)", description:"Estados alterados", toneType: ToneType.ISOCHRONIC, settings:{ carrierFreq:100, pulseFreq:4.5 } },
      { id:'healingGeneralIso', name:"Cura Geral (432Hz Iso)", description:"Harmoniza√ß√£o", toneType: ToneType.ISOCHRONIC, settings:{ carrierFreq:432, pulseFreq:10 } }
    ];

    /************ ParameterInput Component ************/
    function ParameterInput({ label, id, value, onChange, min, max, step = 0.1, unit = "Hz", tooltip = "" }) {
      const [inputValue, setInputValue] = React.useState(String(value));
      const inputRef = React.useRef(null);

      React.useEffect(() => {
        if (inputRef.current !== document.activeElement) setInputValue(String(value));
      }, [value]);

      const handleChange = (e) => {
        const currentStr = e.target.value;
        setInputValue(currentStr);
        if (currentStr === "" || currentStr === "-" || currentStr.endsWith(".")) return;
        const numeric = parseFloat(currentStr);
        if (!isNaN(numeric)) {
          let clamped = numeric;
          if (typeof min === 'number' && isFinite(min) && clamped < min) clamped = min;
          if (typeof max === 'number' && isFinite(max) && clamped > max) clamped = max;
          if (clamped !== value) onChange(clamped);
        }
      };

      const handleBlur = () => {
        let cur = inputValue;
        let numeric = parseFloat(cur);
        let finalVal;
        const numMinDefined = typeof min === 'number' && isFinite(min);
        const numMaxDefined = typeof max === 'number' && isFinite(max);

        if (cur === "") finalVal = numMinDefined ? min : 0;
        else if (isNaN(numeric)) finalVal = value;
        else {
          if (numMinDefined && numeric < min) finalVal = min;
          else if (numMaxDefined && numeric > max) finalVal = max;
          else finalVal = numeric;
        }

        if (typeof step === 'number' && step > 0 && isFinite(finalVal)) {
          finalVal = Math.round(finalVal / step) * step;
          const dp = (String(step).split('.')[1] || '').length;
          if (dp > 0) finalVal = parseFloat(finalVal.toFixed(dp));
        }

        setInputValue(String(finalVal));
        if (finalVal !== value) onChange(finalVal);
      };

      return (
        React.createElement("div", null,
          React.createElement("label", { 
            htmlFor: id, 
            className: "block text-sm font-medium text-gray-300 mb-1",
            title: tooltip || `Ajuste o valor de ${label.toLowerCase()}. Valor m√≠nimo: ${min}, m√°ximo: ${max}, passo: ${step}`
          }, label),
          React.createElement("div", { className: "relative" },
            React.createElement("input", {
              ref: inputRef,
              id, name: id, type: "text", inputMode: "decimal",
              value: inputValue, onChange: handleChange, onBlur: handleBlur,
              "aria-valuemin": typeof min === 'number' && isFinite(min) ? min : undefined,
              "aria-valuemax": typeof max === 'number' && isFinite(max) ? max : undefined,
              className: "w-full px-3 py-2 bg-gray-800 border border-gray-600 rounded-md shadow-sm text-gray-100 placeholder-gray-500 focus:outline-none focus:ring-2 focus:ring-violet-500 sm:text-sm"
            }),
            unit && React.createElement("span", { className: "absolute inset-y-0 right-0 pr-3 flex items-center text-sm text-gray-500 pointer-events-none" }, unit)
          )
        )
      );
    }

    /************ Audio Engine Hook (useAudioEngine) ************/
    function useAudioEngine() {
      const [isPlaying, setIsPlaying] = React.useState(false);
      const audioContextRef = React.useRef(null);
      const masterGainRef = React.useRef(null);

      const osc1Ref = React.useRef(null);
      const osc2Ref = React.useRef(null);
      const panner1Ref = React.useRef(null);
      const panner2Ref = React.useRef(null);
      const isochronicCarrierGainRef = React.useRef(null);
      const pulseLFORef = React.useRef(null);
      const lfoModulatorGainRef = React.useRef(null);
      const currentPlayingTypeRef = React.useRef(null);

      const ensureAudioContext = React.useCallback(async () => {
        if (!audioContextRef.current) {
          try {
            // Criar AudioContext com fallback para navegadores mais antigos
            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
            masterGainRef.current = audioContextRef.current.createGain();
            masterGainRef.current.connect(audioContextRef.current.destination);
            
            // Log para debug
            console.log('‚úÖ AudioContext criado:', audioContextRef.current.state);
          } catch (error) {
            console.error('‚ùå Erro ao criar AudioContext:', error);
            throw new Error('N√£o foi poss√≠vel inicializar o sistema de √°udio');
          }
        }
        
        // Resolver AudioContext se estiver suspenso
        if (audioContextRef.current.state === 'suspended') {
          try {
            console.log('üîÑ Tentando resumir AudioContext suspenso...');
            await audioContextRef.current.resume();
            console.log('‚úÖ AudioContext resumido:', audioContextRef.current.state);
          } catch (error) {
            console.error('‚ùå Erro ao resumir AudioContext:', error);
            throw new Error('N√£o foi poss√≠vel ativar o sistema de √°udio');
          }
        }
        
        // Verificar se o AudioContext est√° funcionando
        if (audioContextRef.current.state !== 'running') {
          console.warn('‚ö†Ô∏è AudioContext n√£o est√° rodando:', audioContextRef.current.state);
          
          // Em dispositivos m√≥veis, tentar uma abordagem diferente
          if (isMobileDevice()) {
            console.log('üì± Dispositivo m√≥vel detectado, tentando abordagem alternativa...');
            try {
              // For√ßar o contexto a funcionar
              await audioContextRef.current.resume();
              console.log('‚úÖ AudioContext for√ßado a funcionar:', audioContextRef.current.state);
            } catch (forceError) {
              console.error('‚ùå Falha ao for√ßar AudioContext:', forceError);
            }
          }
        }
        
        // Verifica√ß√£o final
        if (audioContextRef.current.state === 'running') {
          console.log('üéµ AudioContext funcionando perfeitamente!');
        } else {
          console.warn('‚ö†Ô∏è AudioContext ainda n√£o est√° funcionando:', audioContextRef.current.state);
        }
      }, []);

      const stopAllNodes = React.useCallback((context = audioContextRef.current) => {
        if (!context) return;
        const nodesToStop = [osc1Ref.current, osc2Ref.current, pulseLFORef.current];
        nodesToStop.forEach(node => {
          if (node) { try { node.stop(); } catch(e){} try { node.disconnect(); } catch(e){} }
        });
        osc1Ref.current = null; osc2Ref.current = null; pulseLFORef.current = null;

        const nodesToDisconnect = [panner1Ref.current, panner2Ref.current, lfoModulatorGainRef.current, isochronicCarrierGainRef.current];
        nodesToDisconnect.forEach(node => { if (node) { try { node.disconnect(); } catch(e){} } });
        panner1Ref.current = null; panner2Ref.current = null; lfoModulatorGainRef.current = null; isochronicCarrierGainRef.current = null;

        if (context === audioContextRef.current) currentPlayingTypeRef.current = null;
      }, []);

      const createAudioGraph = React.useCallback((ac, destinationNode, type, settings, nodeRefs) => {
        // Clean existing refs
        Object.values(nodeRefs).forEach(ref => {
          if (ref.current) { try { ref.current.disconnect(); } catch(e){} ref.current = null; }
        });

        switch (type) {
          case ToneType.ISOCHRONIC: {
            const { carrierFreq, pulseFreq } = settings;
            nodeRefs.osc1Ref.current = ac.createOscillator();
            nodeRefs.osc1Ref.current.type = 'sine';
            nodeRefs.osc1Ref.current.frequency.setValueAtTime(carrierFreq, ac.currentTime);

            nodeRefs.isochronicCarrierGainRef.current = ac.createGain();
            nodeRefs.isochronicCarrierGainRef.current.gain.setValueAtTime(0.5, ac.currentTime);

            nodeRefs.pulseLFORef.current = ac.createOscillator();
            nodeRefs.pulseLFORef.current.type = 'sine';
            nodeRefs.pulseLFORef.current.frequency.setValueAtTime(pulseFreq, ac.currentTime);

            nodeRefs.lfoModulatorGainRef.current = ac.createGain();
            nodeRefs.lfoModulatorGainRef.current.gain.setValueAtTime(0.5, ac.currentTime);

            nodeRefs.osc1Ref.current.connect(nodeRefs.isochronicCarrierGainRef.current);
            nodeRefs.isochronicCarrierGainRef.current.connect(destinationNode);

            nodeRefs.pulseLFORef.current.connect(nodeRefs.lfoModulatorGainRef.current);
            nodeRefs.lfoModulatorGainRef.current.connect(nodeRefs.isochronicCarrierGainRef.current.gain);
            break;
          }
          case ToneType.BINAURAL: {
            const { baseFreq, beatFreq } = settings;
            const freqLeft = baseFreq - beatFreq / 2;
            const freqRight = baseFreq + beatFreq / 2;

            nodeRefs.osc1Ref.current = ac.createOscillator();
            nodeRefs.osc1Ref.current.type = 'sine';
            nodeRefs.osc1Ref.current.frequency.setValueAtTime(freqLeft, ac.currentTime);
            nodeRefs.panner1Ref.current = ac.createStereoPanner();
            nodeRefs.panner1Ref.current.pan.setValueAtTime(-1, ac.currentTime);
            nodeRefs.osc1Ref.current.connect(nodeRefs.panner1Ref.current).connect(destinationNode);

            nodeRefs.osc2Ref.current = ac.createOscillator();
            nodeRefs.osc2Ref.current.type = 'sine';
            nodeRefs.osc2Ref.current.frequency.setValueAtTime(freqRight, ac.currentTime);
            nodeRefs.panner2Ref.current = ac.createStereoPanner();
            nodeRefs.panner2Ref.current.pan.setValueAtTime(1, ac.currentTime);
            nodeRefs.osc2Ref.current.connect(nodeRefs.panner2Ref.current).connect(destinationNode);
            break;
          }
          case ToneType.MONAURAL: {
            const { freq1, freq2 } = settings;
            nodeRefs.osc1Ref.current = ac.createOscillator();
            nodeRefs.osc1Ref.current.type = 'sine';
            nodeRefs.osc1Ref.current.frequency.setValueAtTime(freq1, ac.currentTime);
            nodeRefs.osc1Ref.current.connect(destinationNode);

            nodeRefs.osc2Ref.current = ac.createOscillator();
            nodeRefs.osc2Ref.current.type = 'sine';
            nodeRefs.osc2Ref.current.frequency.setValueAtTime(freq2, ac.currentTime);
            nodeRefs.osc2Ref.current.connect(destinationNode);
            break;
          }
        }
      }, []);

            const play = React.useCallback(async (type, settings, globalVolume) => {
        try {
          await ensureAudioContext();
          const ac = audioContextRef.current;
          const masterGain = masterGainRef.current;
          if (!ac || !masterGain) {
            console.error('AudioContext ou MasterGain n√£o dispon√≠vel');
            return;
          }
          stopAllNodes();

          masterGain.gain.setValueAtTime(globalVolume, ac.currentTime);
          currentPlayingTypeRef.current = type;

          const liveNodeRefs = {
            osc1Ref, osc2Ref, panner1Ref, panner2Ref, isochronicCarrierGainRef, pulseLFORef, lfoModulatorGainRef
          };

          createAudioGraph(ac, masterGain, type, settings, liveNodeRefs);

          if (liveNodeRefs.osc1Ref.current) try{ liveNodeRefs.osc1Ref.current.start(ac.currentTime); }catch(e){}
          if (liveNodeRefs.osc2Ref.current) try{ liveNodeRefs.osc2Ref.current.start(ac.currentTime); }catch(e){}
          if (liveNodeRefs.pulseLFORef.current) try{ liveNodeRefs.pulseLFORef.current.start(ac.currentTime); }catch(e){}

          setIsPlaying(true);
        } catch (error) {
          console.error('‚ùå Erro ao reproduzir √°udio:', error);
          
          // Em dispositivos m√≥veis, mostrar mensagem espec√≠fica
          if (isMobileDevice()) {
            if (error.message.includes('sistema de √°udio')) {
              alert('‚ùå Sistema de √°udio n√£o ativado!\n\nüì± Para dispositivos m√≥veis:\n1. Clique no bot√£o "üîä Ativar Sistema de √Åudio"\n2. Aguarde a confirma√ß√£o\n3. Tente reproduzir novamente');
            } else {
              alert('‚ùå Erro ao reproduzir √°udio no celular!\n\nüîß Solu√ß√µes:\n‚Ä¢ Verifique se o volume est√° ligado\n‚Ä¢ Tente ativar o sistema de √°udio novamente\n‚Ä¢ Recarregue a p√°gina se necess√°rio');
            }
          } else {
            alert('‚ùå Erro ao reproduzir √°udio: ' + error.message);
          }
        }
      }, [ensureAudioContext, stopAllNodes, createAudioGraph]);

      const stop = React.useCallback(() => { stopAllNodes(); setIsPlaying(false); }, [stopAllNodes]);

      const setGlobalVolume = React.useCallback((volume) => {
        if (masterGainRef.current && audioContextRef.current) {
          masterGainRef.current.gain.setValueAtTime(volume, audioContextRef.current.currentTime);
        }
      }, []);

      React.useEffect(() => {
        const ac = audioContextRef.current;
        return () => {
          stopAllNodes();
          if (ac && ac.state !== 'closed') {
            ac.close().catch(()=>{});
            audioContextRef.current = null;
            masterGainRef.current = null;
          }
        };
      }, [stopAllNodes]);

      // WAV encoding helpers
      function interleave(inputL, inputR) {
        const length = inputL.length + inputR.length;
        const result = new Float32Array(length);
        let index = 0, inputIndex = 0;
        while (index < length) {
          result[index++] = inputL[inputIndex];
          result[index++] = inputR[inputIndex];
          inputIndex++;
        }
        return result;
      }

      function encodeWAV(audioBuffer) {
        const numChannels = audioBuffer.numberOfChannels;
        const sampleRate = audioBuffer.sampleRate;
        const bitDepth = 16;
        let result;
        if (numChannels === 2) result = interleave(audioBuffer.getChannelData(0), audioBuffer.getChannelData(1));
        else result = audioBuffer.getChannelData(0);

        const dataLength = result.length * (bitDepth / 8);
        const buffer = new ArrayBuffer(44 + dataLength);
        const view = new DataView(buffer);
        let offset = 0;

        function writeString(str) { for (let i=0;i<str.length;i++) view.setUint8(offset++, str.charCodeAt(i)); }

        writeString('RIFF');
        view.setUint32(offset, 36 + dataLength, true); offset += 4;
        writeString('WAVE');
        writeString('fmt ');
        view.setUint32(offset, 16, true); offset += 4;
        view.setUint16(offset, 1, true); offset += 2; // PCM
        view.setUint16(offset, numChannels, true); offset += 2;
        view.setUint32(offset, sampleRate, true); offset += 4;
        view.setUint32(offset, sampleRate * numChannels * (bitDepth/8), true); offset += 4;
        view.setUint16(offset, numChannels * (bitDepth/8), true); offset += 2;
        view.setUint16(offset, bitDepth, true); offset += 2;
        writeString('data');
        view.setUint32(offset, dataLength, true); offset += 4;

        let index = 0;
        while (offset < 44 + dataLength && index < result.length) {
          let sample = result[index++];
          sample = Math.max(-1, Math.min(1, sample));
          sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
          view.setInt16(offset, sample, true);
          offset += 2;
        }
        return new Blob([view], { type: 'audio/wav' });
      }

      const exportAudioAsWav = async (type, settings, globalVolume, durationInSeconds) => {
        const sampleRate = 44100;
        const numChannels = (type === ToneType.BINAURAL) ? 2 : 1;
        const OfflineAC = window.OfflineAudioContext || window.webkitOfflineAudioContext;
        if (!OfflineAC) throw new Error("OfflineAudioContext n√£o suportado no navegador.");

        const offlineCtx = new OfflineAC(numChannels, Math.floor(sampleRate * durationInSeconds), sampleRate);
        const offlineMasterGain = offlineCtx.createGain();
        offlineMasterGain.gain.setValueAtTime(globalVolume, 0);
        offlineMasterGain.connect(offlineCtx.destination);

        const offlineNodeRefs = {
          osc1Ref: { current: null },
          osc2Ref: { current: null },
          panner1Ref: { current: null },
          panner2Ref: { current: null },
          isochronicCarrierGainRef: { current: null },
          pulseLFORef: { current: null },
          lfoModulatorGainRef: { current: null }
        };

        createAudioGraph(offlineCtx, offlineMasterGain, type, settings, offlineNodeRefs);

        if (offlineNodeRefs.osc1Ref.current) try{ offlineNodeRefs.osc1Ref.current.start(0); }catch(e){}
        if (offlineNodeRefs.osc2Ref.current) try{ offlineNodeRefs.osc2Ref.current.start(0); }catch(e){}
        if (offlineNodeRefs.pulseLFORef.current) try{ offlineNodeRefs.pulseLFORef.current.start(0); }catch(e){}

        const rendered = await offlineCtx.startRendering();
        if (!rendered || rendered.length === 0) throw new Error("Render vazio.");
        const wavBlob = encodeWAV(rendered);

        const url = URL.createObjectURL(wavBlob);
        const a = document.createElement('a');
        document.body.appendChild(a);
        a.style.display = 'none';
        a.href = url;
        const timestamp = new Date().toISOString().replace(/[:.]/g,'-');
        a.download = `aura_harmonics_${type.toLowerCase().replace(/\s+/g,'_')}_${timestamp}.wav`;
        a.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(a);
        return true;
      };

      return { play, stop, isPlaying, setGlobalVolume, exportAudioAsWav };
    }

    /************ ControlPanel Component ************/
    function ControlPanel(props) {
      const {
        toneTypesConfig, selectedToneType, onToneTypeChange, settings, onSettingsChange,
        volume, onVolumeChange, onPlayToggle, isPlaying, onExport, exportDuration, onExportDurationChange,
        isExporting, exportStatusMessage, presets, onPresetSelect
      } = props;

      const [isInfoExpanded, setIsInfoExpanded] = React.useState(false);

      const renderSettingsInputs = () => {
        if (selectedToneType === ToneType.ISOCHRONIC) {
          return React.createElement(React.Fragment, null,
            React.createElement(ParameterInput, { 
              label:"Frequ√™ncia Portadora (Hz)", 
              id:"carrierFreq", 
              value: settings.carrierFreq, 
              onChange: v => onSettingsChange({carrierFreq: v}), 
              min: FREQUENCY_RANGES.carrierFreq.min, 
              max: FREQUENCY_RANGES.carrierFreq.max, 
              step: FREQUENCY_RANGES.carrierFreq.step,
              tooltip: "Frequ√™ncia principal do tom isocr√¥nico. Esta √© a frequ√™ncia base que ser√° pulsada para criar o efeito de sincroniza√ß√£o cerebral."
            }),
            React.createElement(ParameterInput, { 
              label:"Frequ√™ncia de Pulso (Hz)", 
              id:"pulseFreq", 
              value: settings.pulseFreq, 
              onChange: v => onSettingsChange({pulseFreq: v}), 
              min: FREQUENCY_RANGES.pulseFreq.min, 
              max: FREQUENCY_RANGES.pulseFreq.max, 
              step: FREQUENCY_RANGES.pulseFreq.step,
              tooltip: "Velocidade com que o tom portador √© ligado e desligado. Frequ√™ncias baixas (0.5-10Hz) s√£o ideais para relaxamento, altas (10-40Hz) para foco."
            })
          );
        } else if (selectedToneType === ToneType.BINAURAL) {
          return React.createElement(React.Fragment, null,
            React.createElement(ParameterInput, { 
              label:"Frequ√™ncia Base (Hz)", 
              id:"baseFreq", 
              value: settings.baseFreq, 
              onChange: v => onSettingsChange({baseFreq: v}), 
              min: FREQUENCY_RANGES.baseFreq.min, 
              max: FREQUENCY_RANGES.baseFreq.max, 
              step: FREQUENCY_RANGES.baseFreq.step,
              tooltip: "Frequ√™ncia central das batidas binaurais. O c√©rebro criar√° batidas na diferen√ßa entre as frequ√™ncias dos dois ouvidos."
            }),
            React.createElement(ParameterInput, { 
              label:"Frequ√™ncia de Batida (Hz)", 
              id:"beatFreq", 
              value: settings.beatFreq, 
              onChange: v => onSettingsChange({beatFreq: v}), 
              min: FREQUENCY_RANGES.beatFreq.min, 
              max: FREQUENCY_RANGES.beatFreq.max, 
              step: FREQUENCY_RANGES.beatFreq.step,
              tooltip: "Frequ√™ncia da batida percebida pelo c√©rebro. Delta (0.5-4Hz): sono profundo, Theta (4-8Hz): medita√ß√£o, Alpha (8-13Hz): relaxamento, Beta (13-30Hz): foco."
            })
          );
        } else {
          return React.createElement(React.Fragment, null,
            React.createElement(ParameterInput, { 
              label:"Frequ√™ncia 1 (Hz)", 
              id:"freq1", 
              value: settings.freq1, 
              onChange: v => onSettingsChange({freq1: v}), 
              min: FREQUENCY_RANGES.freq1.min, 
              max: FREQUENCY_RANGES.freq1.max, 
              step: FREQUENCY_RANGES.freq1.step,
              tooltip: "Primeira frequ√™ncia para criar batidas monaurais. Esta frequ√™ncia ser√° misturada com a segunda para criar o efeito desejado."
            }),
            React.createElement(ParameterInput, { 
              label:"Frequ√™ncia 2 (Hz)", 
              id:"freq2", 
              value: settings.freq2, 
              onChange: v => onSettingsChange({freq2: v}), 
              min: FREQUENCY_RANGES.freq2.min, 
              max: FREQUENCY_RANGES.freq2.max, 
              step: FREQUENCY_RANGES.freq2.step,
              tooltip: "Segunda frequ√™ncia para criar batidas monaurais. A diferen√ßa entre as duas frequ√™ncias determina o efeito percebido."
            })
          );
        }
      };

      return (
        React.createElement("div", { className: "space-y-6" },
          React.createElement("div", { className: "p-1 bg-gray-700 rounded-lg flex space-x-1" },
            toneTypesConfig.map(tone => {
              let tooltipText = "";
              switch (tone.id) {
                case ToneType.ISOCHRONIC:
                  tooltipText = "Tons isocr√¥nicos s√£o pulsos de som que se ligam e desligam em uma frequ√™ncia espec√≠fica. Eles podem ajudar na sincroniza√ß√£o das ondas cerebrais para foco, relaxamento e medita√ß√£o.";
                  break;
                case ToneType.BINAURAL:
                  tooltipText = "Batidas binaurais s√£o criadas quando dois tons de frequ√™ncias ligeiramente diferentes s√£o apresentados separadamente para cada ouvido. O c√©rebro percebe a diferen√ßa como uma batida r√≠tmica que pode influenciar estados mentais.";
                  break;
                case ToneType.MONAURAL:
                  tooltipText = "Batidas monaurais s√£o criadas quando dois tons de frequ√™ncias diferentes s√£o misturados antes de chegarem aos ouvidos. Eles podem ajudar na concentra√ß√£o e relaxamento.";
                  break;
              }
              return React.createElement("button", {
                key: tone.id,
                onClick: () => onToneTypeChange(tone.id),
                disabled: isPlaying || isExporting,
                title: tooltipText,
                className: `w-full py-2.5 px-4 rounded-md text-sm font-medium transition-colors duration-150 focus:outline-none ${selectedToneType === tone.id ? 'bg-violet-600 text-white shadow-md' : 'text-gray-300 hover:bg-gray-600 hover:text-white'} disabled:opacity-60 disabled:cursor-not-allowed`
              }, tone.label);
            })
          ),

          React.createElement("div", { className: "p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("h3", { className: "text-lg font-medium text-gray-200 mb-3" }, "Presets"),
            React.createElement("div", { className: "grid grid-cols-2 sm:grid-cols-3 gap-2" },
              presets.map(p => {
                let detailedTooltip = "";
                switch (p.id) {
                  case 'focusAlphaBinaural':
                    detailedTooltip = "Foco (Alpha Binaural): Frequ√™ncia de 10Hz para clareza mental e concentra√ß√£o. Ideal para estudos, trabalho e atividades que requerem aten√ß√£o.";
                    break;
                  case 'meditationThetaBinaural':
                    detailedTooltip = "Medita√ß√£o (Theta Binaural): Frequ√™ncia de 6Hz para relaxamento profundo e medita√ß√£o. Ajuda a alcan√ßar estados de consci√™ncia alterados.";
                    break;
                  case 'solfeggio528Iso':
                    detailedTooltip = "Solfeggio 528Hz (Iso): Frequ√™ncia conhecida como 'frequ√™ncia do amor'. Promove equil√≠brio emocional, transforma√ß√£o e cura.";
                    break;
                  case 'solfeggio396Monaural':
                    detailedTooltip = "Solfeggio 396Hz (Mon): Frequ√™ncia para libera√ß√£o de medos e culpas. Ajuda a limpar bloqueios emocionais e traumas.";
                    break;
                  case 'astralProjectionThetaIso':
                    detailedTooltip = "Proje√ß√£o Astral (Theta Iso): Frequ√™ncia de 4.5Hz para estados alterados de consci√™ncia e experi√™ncias transcendentais.";
                    break;
                  case 'healingGeneralIso':
                    detailedTooltip = "Cura Geral (432Hz Iso): Frequ√™ncia harmonizadora que promove equil√≠brio f√≠sico, mental e espiritual.";
                    break;
                }
                return React.createElement("button", {
                  key: p.id, onClick: () => onPresetSelect(p.id), disabled: isExporting,
                  title: detailedTooltip,
                  className: "px-3 py-2 text-xs font-medium text-center text-white bg-violet-500 rounded-lg hover:bg-violet-600 focus:outline-none disabled:opacity-50 disabled:cursor-not-allowed truncate"
                }, p.name);
              })
            )
          ),

          React.createElement("div", { className: "grid grid-cols-1 md:grid-cols-2 gap-x-6 gap-y-4 p-4 bg-gray-700/50 rounded-lg" }, renderSettingsInputs()),

          React.createElement("div", { className: "p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("label", { 
              htmlFor:"volume", 
              className:"block text-sm font-medium text-gray-300 mb-1",
              title: "Controla o volume geral de todos os sons gerados. Ajuste conforme sua prefer√™ncia e ambiente de uso."
            }, "Volume Principal"),
            React.createElement("div", { className:"flex items-center space-x-3" },
              React.createElement("input", {
                id:"volume", type:"range", min:0, max:1, step:0.01, value: volume,
                onChange: e => onVolumeChange(parseFloat(e.target.value)),
                disabled: isExporting,
                className: "w-full h-2 bg-gray-600 rounded-lg appearance-none cursor-pointer"
              }),
              React.createElement("span", { className: "text-sm text-gray-400 w-12 text-right" }, `${(volume*100).toFixed(0)}%`)
            )
          ),

          React.createElement("div", { className: "flex justify-center items-center space-x-4 pt-4" },
            React.createElement("button", {
              onClick: onPlayToggle, disabled: isExporting,
              "aria-label": isPlaying ? 'Pausar' : 'Reproduzir',
              title: isPlaying ? "Clique para pausar a reprodu√ß√£o do √°udio atual" : "Clique para iniciar a reprodu√ß√£o do √°udio com as configura√ß√µes selecionadas",
              className: `p-4 rounded-full transition-all duration-150 focus:outline-none ${isPlaying ? 'bg-teal-500 text-white' : 'bg-green-500 text-white'} disabled:opacity-60 disabled:cursor-not-allowed`
            }, isPlaying ? "Pausar" : "Reproduzir"),
            React.createElement("button", {
              onClick: () => { if (isPlaying) onPlayToggle(); }, disabled: !isPlaying || isExporting,
              title: "Clique para parar completamente a reprodu√ß√£o do √°udio e retornar ao estado inicial",
              className: "p-4 bg-red-500 text-white rounded-full transition-all duration-150 hover:bg-red-600 focus:outline-none disabled:opacity-50 disabled:cursor-not-allowed"
            }, "Parar")
          ),

          React.createElement("div", { className: "mt-6 pt-6 border-t border-gray-700 space-y-4 p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("h3", { className: "text-lg font-medium text-gray-200" }, "Exportar √Åudio"),
            React.createElement(ParameterInput, { 
              label:"Dura√ß√£o (minutos)", 
              id:"exportDuration", 
              value: exportDuration, 
              onChange: onExportDurationChange, 
              min: MIN_EXPORT_DURATION_MINUTES, 
              max: MAX_EXPORT_DURATION_MINUTES, 
              step:1, 
              unit:"min",
              tooltip: "Define a dura√ß√£o do arquivo de √°udio exportado. Arquivos mais longos levam mais tempo para processar, mas permitem sess√µes mais extensas."
            }),
            React.createElement("button", {
              onClick: onExport, disabled: isPlaying || isExporting,
              title: "Exporta o √°udio atual como arquivo WAV para download. O arquivo ser√° salvo com a dura√ß√£o especificada e as configura√ß√µes atuais de frequ√™ncia e volume.",
              className: "w-full py-2.5 px-4 rounded-md text-sm font-medium bg-emerald-600 hover:bg-emerald-700 text-white focus:outline-none disabled:opacity-50 disabled:cursor-not-allowed"
            }, isExporting ? "Exportando..." : "Exportar como WAV"),
            React.createElement("p", { className: "text-xs text-gray-400 text-center export-status" }, exportStatusMessage)
          ),

          React.createElement("div", { className: "mt-6 pt-6 border-t border-gray-700 p-4 bg-gray-700/50 rounded-lg" },
            React.createElement("button", {
              onClick: () => setIsInfoExpanded(!isInfoExpanded),
              className: "w-full text-left text-lg font-medium text-gray-200 hover:text-violet-400 transition-colors flex justify-between items-center",
              "aria-expanded": isInfoExpanded,
              title: "Clique para expandir/recolher informa√ß√µes sobre frequ√™ncias sonoras espec√≠ficas e seus efeitos terap√™uticos conhecidos"
            }, "Informa√ß√µes sobre Frequ√™ncias Sonoras",
              React.createElement("svg", { className: `w-5 h-5 transform ${isInfoExpanded ? 'rotate-180' : 'rotate-0'}`, fill:"none", stroke:"currentColor", viewBox:"0 0 24 24" },
                React.createElement("path", { strokeLinecap:"round", strokeLinejoin:"round", strokeWidth:"2", d:"M19 9l-7 7-7-7" })
              )
            ),
            isInfoExpanded && React.createElement("div", { className: "mt-3 text-xs text-gray-400 space-y-2" },
              React.createElement("p", null, "As frequ√™ncias sonoras (Hz) t√™m usos em √°udio e terapias sonoras; use com responsabilidade."),
              React.createElement("ul", { className: "list-disc list-inside pl-2" },
                React.createElement("li", null, React.createElement("strong", null, "174 Hz:"), " Al√≠vio de estresse."),
                React.createElement("li", null, React.createElement("strong", null, "396 Hz:"), " Libera√ß√£o de medo."),
                React.createElement("li", null, React.createElement("strong", null, "528 Hz:"), " Transforma√ß√£o emocional.")
              )
            )
          )
        )
      );
    }

    /************ App Component ************/
    function App() {
      const [selectedToneType, setSelectedToneType] = React.useState(ToneType.ISOCHRONIC);
      const [isochronicSettings, setIsochronicSettings] = React.useState(DEFAULT_ISOCHRONIC_SETTINGS);
      const [binauralSettings, setBinauralSettings] = React.useState(DEFAULT_BINAURAL_SETTINGS);
      const [monauralSettings, setMonauralSettings] = React.useState(DEFAULT_MONAURAL_SETTINGS);
      const [volume, setVolume] = React.useState(DEFAULT_VOLUME);
      const [audioContextActivated, setAudioContextActivated] = React.useState(false);

      const [exportDuration, setExportDuration] = React.useState(DEFAULT_EXPORT_DURATION_MINUTES);
      const [isExporting, setIsExporting] = React.useState(false);
      const [exportStatusMessage, setExportStatusMessage] = React.useState("");

      const audio = useAudioEngine();
      const { play, stop, isPlaying, setGlobalVolume, exportAudioAsWav } = audio;

      // Verificar se √© dispositivo m√≥vel e mostrar instru√ß√µes
      React.useEffect(() => {
        if (isMobileDevice()) {
          console.log('üì± Dispositivo m√≥vel detectado');
          console.log('User Agent:', navigator.userAgent);
          console.log('Touch Points:', navigator.maxTouchPoints);
          console.log('Largura da tela:', window.innerWidth);
          
          // Mostrar instru√ß√µes espec√≠ficas para m√≥veis
          setTimeout(() => {
            if (!audioContextActivated) {
              console.log('üí° Mostrando instru√ß√µes para dispositivo m√≥vel');
            }
          }, 1000);
        }
      }, [audioContextActivated]);

      // Fun√ß√£o para ativar o AudioContext em dispositivos m√≥veis
      const activateAudioContext = React.useCallback(async () => {
        if (isMobileDevice() && !audioContextActivated) {
          try {
            console.log('Tentando ativar AudioContext para dispositivo m√≥vel...');
            
            // Criar um AudioContext tempor√°rio para ativar o sistema
            const tempContext = new (window.AudioContext || window.webkitAudioContext)();
            console.log('AudioContext tempor√°rio criado, estado:', tempContext.state);
            
            // Tentar resumir o contexto
            if (tempContext.state === 'suspended') {
              await tempContext.resume();
              console.log('AudioContext tempor√°rio resumido, estado:', tempContext.state);
            }
            
            // Criar um oscilador tempor√°rio para "despertar" o sistema
            const tempOsc = tempContext.createOscillator();
            const tempGain = tempContext.createGain();
            tempGain.gain.setValueAtTime(0, 0); // Volume 0 para n√£o fazer barulho
            tempOsc.connect(tempGain);
            tempGain.connect(tempContext.destination);
            tempOsc.start(0);
            tempOsc.stop(0.1);
            
            // Aguardar um pouco e fechar
            setTimeout(() => {
              tempContext.close();
              console.log('AudioContext tempor√°rio fechado');
            }, 100);
            
            setAudioContextActivated(true);
            console.log('‚úÖ AudioContext ativado com sucesso para dispositivo m√≥vel');
            
            // Mostrar mensagem de sucesso
            alert('‚úÖ Sistema de √°udio ativado! Agora voc√™ pode reproduzir sons.');
            
          } catch (error) {
            console.error('‚ùå Erro ao ativar AudioContext:', error);
            alert('‚ùå Erro ao ativar √°udio: ' + error.message);
          }
        }
      }, [audioContextActivated]);

      const getCurrentSettings = React.useCallback(() => {
        switch (selectedToneType) {
          case ToneType.ISOCHRONIC: return isochronicSettings;
          case ToneType.BINAURAL: return binauralSettings;
          case ToneType.MONAURAL: return monauralSettings;
          default: return DEFAULT_ISOCHRONIC_SETTINGS;
        }
      }, [selectedToneType, isochronicSettings, binauralSettings, monauralSettings]);

      const handlePlayToggle = React.useCallback(() => {
        if (isExporting) return;
        if (isPlaying) stop();
        else play(selectedToneType, getCurrentSettings(), volume);
      }, [isPlaying, play, stop, selectedToneType, getCurrentSettings, volume, isExporting]);

      React.useEffect(() => {
        if (isPlaying && !isExporting) {
          play(selectedToneType, getCurrentSettings(), volume);
        }
        // eslint-disable-next-line
      }, [selectedToneType, isochronicSettings, binauralSettings, monauralSettings, volume]);

      React.useEffect(() => { return () => { if (isPlaying) stop(); }; }, [stop, isPlaying]);

      const updateSettings = (newSettings) => {
        if (isExporting) return;
        switch (selectedToneType) {
          case ToneType.ISOCHRONIC: setIsochronicSettings(prev => ({...prev, ...newSettings})); break;
          case ToneType.BINAURAL: setBinauralSettings(prev => ({...prev, ...newSettings})); break;
          case ToneType.MONAURAL: setMonauralSettings(prev => ({...prev, ...newSettings})); break;
        }
      };

      const handleToneTypeChange = (type) => { if (isPlaying || isExporting) return; setSelectedToneType(type); };

      const handleVolumeChange = (vol) => { if (isExporting) return; setVolume(vol); setGlobalVolume(vol); };

      const handleExportDurationChange = (dur) => {
        if (isExporting) return;
        let newDur = Math.max(MIN_EXPORT_DURATION_MINUTES, Math.min(dur, MAX_EXPORT_DURATION_MINUTES));
        if (isNaN(newDur) || !isFinite(newDur)) newDur = DEFAULT_EXPORT_DURATION_MINUTES;
        setExportDuration(newDur);
      };

      const handleExport = React.useCallback(async () => {
        if (isExporting || isPlaying) {
          setExportStatusMessage(isPlaying ? "Pare a reprodu√ß√£o antes de exportar." : "Exporta√ß√£o j√° em andamento.");
          return;
        }

        setIsExporting(true);
        setExportStatusMessage("Inicializando exporta√ß√£o...");
        try {
          setExportStatusMessage("Renderizando √°udio... Aguarde.");
          await exportAudioAsWav(selectedToneType, getCurrentSettings(), volume, exportDuration * 60);
          setExportStatusMessage("Exporta√ß√£o conclu√≠da! Verifique seus downloads.");
        } catch (err) {
          console.error("Export failed:", err);
          setExportStatusMessage(`Falha na exporta√ß√£o: ${err.message || 'Erro desconhecido'}`);
        } finally {
          setIsExporting(false);
          setTimeout(()=>setExportStatusMessage(""), 7000);
        }
      }, [isExporting, isPlaying, exportAudioAsWav, selectedToneType, getCurrentSettings, volume, exportDuration]);

      const handlePresetSelect = React.useCallback((presetId) => {
        if (isExporting) return;
        const preset = PRESETS.find(p => p.id === presetId);
        if (!preset) return;
        setSelectedToneType(preset.toneType);
        switch (preset.toneType) {
          case ToneType.ISOCHRONIC: setIsochronicSettings(preset.settings); break;
          case ToneType.BINAURAL: setBinauralSettings(preset.settings); break;
          case ToneType.MONAURAL: setMonauralSettings(preset.settings); break;
        }
      }, [isExporting]);

      return (
        React.createElement("div", { 
          className: "min-h-screen bg-gray-900 text-gray-100 flex flex-col items-center justify-center p-4",
          onTouchStart: activateAudioContext,
          onClick: activateAudioContext,
          onTouchMove: activateAudioContext,
          onTouchEnd: activateAudioContext
        },
          React.createElement("div", { className: "w-full max-w-2xl bg-gray-800 shadow-2xl rounded-xl p-6 md:p-8" },
            React.createElement("header", { className: "mb-8 text-center" },
              React.createElement("h1", { className: "text-4xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-violet-400 to-fuchsia-500" }, "Aura Harmonics"),
              React.createElement("p", { className: "text-gray-400 mt-2" }, "Crie sua experi√™ncia auditiva para foco, relaxamento ou medita√ß√£o."),
              isMobileDevice() && React.createElement("div", { 
                className: `mt-4 p-3 border rounded-lg text-sm transition-colors duration-300 ${
                  audioContextActivated 
                    ? 'bg-green-900/30 border-green-500/30 text-green-200' 
                    : 'bg-blue-900/30 border-blue-500/30 text-blue-200'
                }` 
              }, 
                React.createElement("p", { className: "font-medium mb-1" }, 
                  audioContextActivated ? "‚úÖ √Åudio Ativado" : "üì± Dispositivo M√≥vel Detectado"
                ),
                React.createElement("p", { className: "mb-3" }, 
                  audioContextActivated 
                    ? "O sistema de √°udio est√° ativo! Voc√™ pode reproduzir sons agora." 
                    : "Para reproduzir √°udio, clique no bot√£o abaixo para ativar o sistema."
                ),
                !audioContextActivated && React.createElement("button", {
                  onClick: activateAudioContext,
                  className: "w-full py-2 px-4 bg-blue-600 hover:bg-blue-700 text-white rounded-md font-medium transition-colors",
                  title: "Clique para ativar o sistema de √°udio no seu dispositivo m√≥vel"
                }, "üîä Ativar Sistema de √Åudio")
              )
            ),
            React.createElement("main", null,
              React.createElement(ControlPanel, {
                toneTypesConfig: TONE_TYPES_CONFIG,
                selectedToneType,
                onToneTypeChange: handleToneTypeChange,
                settings: getCurrentSettings(),
                onSettingsChange: updateSettings,
                volume,
                onVolumeChange: handleVolumeChange,
                onPlayToggle: handlePlayToggle,
                isPlaying,
                onExport: handleExport,
                exportDuration,
                onExportDurationChange: handleExportDurationChange,
                isExporting,
                exportStatusMessage,
                presets: PRESETS,
                onPresetSelect: handlePresetSelect
              })
            ),
            React.createElement("footer", { className: "mt-8 text-center text-gray-500 text-sm" },
              React.createElement("p", null, `¬© ${new Date().getFullYear()} Aura Harmonics. Todos os direitos reservados.`),
              React.createElement("p", { className: "mt-1" }, "Experimente com responsabilidade. N√£o √© um dispositivo m√©dico.")
            )
          )
        )
      );
    }

    /************ Mount App ************/
    const rootEl = document.getElementById('root');
    const root = createRoot(rootEl);
    root.render(React.createElement(React.StrictMode, null, React.createElement(App, null)));
  </script>
</body>
</html>
